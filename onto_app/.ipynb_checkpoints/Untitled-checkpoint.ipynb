{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import *\n",
    "engine = create_engine('sqlite:///onto.db', echo = False)\n",
    "c = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:20:25,575 INFO sqlalchemy.engine.base.Engine DELETE FROM final_node_decisions;\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:DELETE FROM final_node_decisions;\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:20:25,583 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:20:25,587 INFO sqlalchemy.engine.base.Engine COMMIT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:COMMIT\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x14229bfd0>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = engine.connect()\n",
    "c.execution_options(autocommit=True).execute(\"DELETE FROM final_node_decisions;\")\n",
    "# results.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 01:11:19,622 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 01:11:19,632 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 01:11:19,640 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 01:11:19,644 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 01:11:19,648 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 01:11:19,666 INFO sqlalchemy.engine.base.Engine SELECT * FROM node_decisions INNER JOIN nodes ON node_decisions.node_id =nodes.id \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:SELECT * FROM node_decisions INNER JOIN nodes ON node_decisions.node_id =nodes.id \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 01:11:19,683 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 4, 1, 1324455346191020032, 4, 1, \"https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Domino'SPizza\"),\n",
       " (2, 3, 0, 1324455346191020032, 3, 1, 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Peri-Peri'),\n",
       " (3, 2, 1, 1324455346191020032, 2, 1, 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Marinara'),\n",
       " (4, 1, 1, 1324455346191020032, 1, 1, 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#TandooriPizza'),\n",
       " (5, 5, 1, 1324455346191020032, 5, 1, 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#IndianPizza'),\n",
       " (6, 5, 1, 1324449088826343424, 5, 1, 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#IndianPizza'),\n",
       " (7, 1, 1, 1324449088826343424, 1, 1, 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#TandooriPizza'),\n",
       " (8, 3, 1, 1324449088826343424, 3, 1, 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Peri-Peri'),\n",
       " (9, 2, 1, 1324449088826343424, 2, 1, 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Marinara'),\n",
       " (10, 4, 1, 1324449088826343424, 4, 1, \"https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Domino'SPizza\")]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('sqlite:///onto.db', echo = True)\n",
    "    # conn = sqlite3.connect('onto.db')\n",
    "    # c = conn.cursor()\n",
    "c = engine.connect()\n",
    "trans = c.begin()\n",
    "query = \"\"\"SELECT * FROM node_decisions INNER JOIN nodes ON node_decisions.node_id =nodes.id \"\"\"\n",
    "result = c.execute(query)\n",
    "result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:14:12,230 INFO sqlalchemy.engine.base.Engine SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:SELECT CAST('test plain returns' AS VARCHAR(60)) AS anon_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:14:12,233 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:14:12,241 INFO sqlalchemy.engine.base.Engine SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:SELECT CAST('test unicode returns' AS VARCHAR(60)) AS anon_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:14:12,244 INFO sqlalchemy.engine.base.Engine ()\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:14:12,249 INFO sqlalchemy.engine.base.Engine BEGIN (implicit)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:BEGIN (implicit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:14:12,256 INFO sqlalchemy.engine.base.Engine SELECT domain, range, property FROM class_relations \n",
      "        INNER JOIN final_class_decisions ON class_relations.id = final_class_decisions.relation_id\n",
      "        INNER JOIN ontologies ON class_relations.onto_id = ontologies.id\n",
      "        WHERE ontologies.name = :name AND final_class_decisions.approved != 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:SELECT domain, range, property FROM class_relations \n",
      "        INNER JOIN final_class_decisions ON class_relations.id = final_class_decisions.relation_id\n",
      "        INNER JOIN ontologies ON class_relations.onto_id = ontologies.id\n",
      "        WHERE ontologies.name = :name AND final_class_decisions.approved != 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-12-13 02:14:12,261 INFO sqlalchemy.engine.base.Engine {'name': 'pizza'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sqlalchemy.engine.base.Engine:{'name': 'pizza'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Pizza', \"https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Domino'SPizza\", 'hasInstance'),\n",
       " ('https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Peri-Peri', 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Pizza', 'subclassOf'),\n",
       " ('https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Marinara', 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#Pizza', 'isToppingOf'),\n",
       " ('https://serc.iiit.ac.in/downloads/ontology/pizza.owl#TandooriPizza', 'https://serc.iiit.ac.in/downloads/ontology/pizza.owl#IndianPizza', 'subclassOf')]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine = create_engine('sqlite:///onto.db', echo = True)\n",
    "    # conn = sqlite3.connect('onto.db')\n",
    "    # c = conn.cursor()\n",
    "c = engine.connect()\n",
    "trans = c.begin()\n",
    "query = \"\"\"SELECT domain, range, property FROM class_relations \n",
    "        INNER JOIN final_class_decisions ON class_relations.id = final_class_decisions.relation_id\n",
    "        INNER JOIN ontologies ON class_relations.onto_id = ontologies.id\n",
    "        WHERE ontologies.name = :name AND final_class_decisions.approved != 0\"\"\"\n",
    "result = c.execute(query, {'name': 'pizza'})\n",
    "result.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "\n",
    "from re import finditer\n",
    "def split_by_camel_case(identifier):\n",
    "    # Split string by camel-case\n",
    "    matches = finditer('.+?(?:(?<=[a-z])(?=[A-Z])|(?<=[A-Z])(?=[A-Z][a-z])|$)', identifier)\n",
    "    return \" \".join([m.group(0) for m in matches])\n",
    "\n",
    "ont = get_ontology(\"data/input/ontologies/pizza.owl\").load()\n",
    "ont_classes = list(ont.classes())\n",
    "classes = [split_by_camel_case(elem.label.first()).lower() for elem in ont_classes]\n",
    "\n",
    "##if term1 not in set(classes) or term2 in set(classes):\n",
    "    ##append it\n",
    "# idx1 = classes.index(term1) \n",
    "# idx2 = classes.index(term2)\n",
    "# ont_classes[idx1], ont_classes[idx2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition for singly-linked list.\n",
    "class ListNode:\n",
    "    def __init__(self, val=0, next=None):\n",
    "        self.val = val\n",
    "        self.next = next\n",
    "class Solution:\n",
    "    def getNum(self, node):\n",
    "        l = []\n",
    "        currNode = node\n",
    "        while currNode:\n",
    "            l.append(str(currNode.val))\n",
    "            currNode = currNode.next\n",
    "        num = int(''.join(l[::-1]))\n",
    "        return num\n",
    "        \n",
    "    def addTwoNumbers(self, l1: ListNode, l2: ListNode) -> ListNode:\n",
    "        n1 = self.getNum(l1)\n",
    "        n2 = self.getNum(l2)\n",
    "        print (n1, n2)\n",
    "        added = str(n1 + n2)\n",
    "        finalnodes = []\n",
    "        for intg in added[::-1]:\n",
    "            finalnodes.append(ListNode(intg))\n",
    "        for i,f in enumerate(finalnodes[:-1]):\n",
    "            f.next = finalnodes[i+1]\n",
    "        finalnodes[-1].next = None\n",
    "        return finalnodes[0]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08158884942531586\n",
      "-0.013144171796739101\n",
      "0.18724821507930756\n",
      "0.03891165927052498\n",
      "-0.018427757546305656\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "from scipy import spatial\n",
    "# USE_link = \"https://tfhub.dev/google/universal-sentence-encoder-large/5?tf-hub-format=compressed\"\n",
    "# model = hub.load(USE_link)\n",
    "\n",
    "def extractUSEEmbeddings(words):\n",
    "    word_embeddings = model(words)\n",
    "    return word_embeddings.numpy()\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    # Returns cosine similarity of two vectors\n",
    "    return 1 - spatial.distance.cosine(a, b)\n",
    "\n",
    "def generateScore(text_array):\n",
    "    all_embs = extractUSEEmbeddings(text_array + [\"Pizza\"])\n",
    "    return [cos_sim(tweet_emb, all_embs[-1]) for tweet_emb in all_embs[:-1]]\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Solve challenges for patients with skin of color at Hacking Dermatology on Oct 23-25th. Challenge areas include diagnostic accuracy, personalized care, and clinical trial representation! Register now at http://hackingdermatology.org to join.\", \"Information Security\"])))\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Btw, holiday wishes guys - Christmas is around the corner soon!\", \"Information Security\"])))\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Looks like my computer got hacked :/\", \"Information Security\"])))\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Did you all know that Valentina Mussi from Miami popularised what came to be known as pizza cereals â€” salty cereals in the shape of mini pizzas\", \"Information Security\"])))\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Have you all ever tried the butter chicken pizza? It is a perfect blend of desi butter chicken with exotic cheese and native Italian cuisine\", \"Information Security\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.007294975686818361\n",
      "0.24479424953460693\n",
      "-0.02466479316353798\n",
      "0.23844434320926666\n",
      "0.21493417024612427\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "from scipy import spatial\n",
    "# USE_link = \"https://tfhub.dev/google/universal-sentence-encoder-large/5?tf-hub-format=compressed\"\n",
    "# model = hub.load(USE_link)\n",
    "\n",
    "def extractUSEEmbeddings(words):\n",
    "    word_embeddings = model(words)\n",
    "    return word_embeddings.numpy()\n",
    "\n",
    "def cos_sim(a,b):\n",
    "    # Returns cosine similarity of two vectors\n",
    "    return 1 - spatial.distance.cosine(a, b)\n",
    "\n",
    "def generateScore(text_array):\n",
    "    all_embs = extractUSEEmbeddings(text_array + [\"Pizza\"])\n",
    "    return [cos_sim(tweet_emb, all_embs[-1]) for tweet_emb in all_embs[:-1]]\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Oh god, a new strain of coronavirus in the UK?! When will this end??\", \"Information Security\"])))\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Cyber-attacks such as phishing, identity theft, social engineering, e-mail spoofing, ransomware etc. have increased significantly, with a 140% increase worldwide during the COVID-19 pandemic :/\", \"Information Security\"])))\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Bored at home today - Might order pizza for dinner, with extra cheese of course\", \"Information Security\"])))\n",
    "print (cos_sim(*extractUSEEmbeddings([\"According to cybersecurity firm Check Point Software Technologies, India has become vulnerable to ransomware attacks in the 3rd quarter of this year. 71% of global respondents, including Indians, reported an increase in cyberattacks during February-March 2020\", \"Information Security\"])))\n",
    "print (cos_sim(*extractUSEEmbeddings([\"Organisations need to acknowledge that understanding and quantifying risk is critical to building an effective security programme in this day and age. Solely orchestrating and automating security actions with an intelligence-led approach is not enough.\", \"Information Security\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asset owned by organization'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
